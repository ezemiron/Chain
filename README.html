<!DOCTYPE HTML>
<html>
 <head>
  <meta charset="utf-8"/>
  <title>
   Made with Remarkable!
  </title>
  <link href="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.1/styles/github.min.css" rel="stylesheet"/>
  <style type="text/css">
   body,table tr{background-color:#fff}table tr td,table tr th{border:1px solid #ccc;text-align:left;padding:6px 13px;margin:0}pre code,table,table tr{padding:0}hr,pre code{background:0 0}body{font:16px Helvetica,Arial,sans-serif;line-height:1.4;color:#333;word-wrap:break-word;padding:10px 15px}strong,table tr th{font-weight:700}h1{font-size:2em;margin:.67em 0;text-align:center}h2{font-size:1.75em}h3{font-size:1.5em}h4{font-size:1.25em}h1,h2,h3,h4,h5,h6{font-weight:700;position:relative;margin-top:15px;margin-bottom:15px;line-height:1.1}h1,h2{border-bottom:1px solid #eee}hr{height:0;margin:15px 0;overflow:hidden;border:0;border-bottom:1px solid #ddd}a{color:#4183C4}a.absent{color:#c00}ol,ul{padding-left:15px;margin-left:5px}ol{list-style-type:lower-roman}table tr{border-top:1px solid #ccc;margin:0}table tr:nth-child(2n){background-color:#aaa}table tr td :first-child,table tr th :first-child{margin-top:0}table tr td:last-child,table tr th :last-child{margin-bottom:0}img{max-width:100%}blockquote{padding:0 15px;border-left:4px solid #ccc}code,tt{margin:0 2px;padding:0 5px;white-space:nowrap;border:1px solid #eaeaea;background-color:#f8f8f8;border-radius:3px}pre code{margin:0;white-space:pre;border:none}.highlight pre,pre{background-color:#f8f8f8;border:1px solid #ccc;font-size:13px;line-height:19px;overflow:auto;padding:6px 10px;border-radius:3px}
  </style>
 </head>
 <body>
  <h1 id="chain-chain-analysis-of-the-in-situ-nucleome">
   Cha
   <em>
    i
   </em>
   N - Cha
   <em>
    i
   </em>
   N analysis of the
   <em>
    in situ
   </em>
   Nucleome
  </h1>
  <h2 id="what">
   What?
  </h2>
  <p>
   A tool to dissect the spatial distribution of the mammalian nucleome relative to chromatin from super resolution 3D structured illumination microscopy (3D SIM) data. This tool was developed as part of my doctoral thesis and was used in a related publication.
  </p>
  <h2 id="where">
   Where?
  </h2>
  <p>
   The original versions of Cha
   <em>
    i
   </em>
   N are currently in the Oxford biochemistry Micron servers under
   <code>
    wolf4192/Chain/
   </code>
   <br/>
   And in github:
   <a href="mailto:git@github.com">
    git@github.com
   </a>
   :ezemiron/Chain.git
   <br/>
   <a href="https://github.com/ezemiron/Chain.git">
    https://github.com/ezemiron/Chain.git
   </a>
  </p>
  <p>
   One version exists for 2 Channel data with chromatin in second channel and spots channel in first
   <br/>
   and another version for 3 channel data, with chromatin in third channel and spots channel in first and second and channel.
  </p>
  <h5 id="older-versions">
   Older versions:
  </h5>
  <p>
   Only for 2 channels:
   <br/>
   <code>
    wolf4192/backup-chain/eze7134/Documents/papers/chrom_marks/
   </code>
  </p>
  <h3 id="requirements-and-set-up">
   Requirements and set up
  </h3>
  <p>
   First you should check you have all the necessary…
  </p>
  <h4 id="r-at-least-r-33">
   R:     at least R 3.3
  </h4>
  <pre><code>bioimagetools: (source code: https://r-forge.r-project.org/R/?group_id=1143 )

 $ R
    R version 3.3.3 (2017-03-06) -- "Another Canoe"
    Copyright (C) 2017 The R Foundation for Statistical Computing
    Platform: x86_64-pc-linux-gnu (64-bit)
    [...]
    &gt; setRepositories(ind=c(1,2))
    &gt; install.packages("bioimagetools")
    Installing package into ‘/usr/local/lib/R/site-library’
    (as ‘lib’ is unspecified)
    Warning in install.packages("bioimagetools") :
      'lib = "/usr/local/lib/R/site-library"' is not writable
    Would you like to use a personal library instead?  (y/n) y
    Would you like to create a personal library
    ~/R/x86_64-pc-linux-gnu-library/3.3
    to install packages into?  (y/n) y
    --- Please select a CRAN mirror for use in this session ---
    [...]
    Selection: 67
    also installing the dependencies ‘jpeg’, ‘locfit’, ‘fftwtools’, ‘tiff’, ‘EBImage’
    [...]
    * DONE (bioimagetools)
    [...]
    &gt; library('bioimagetools')
    Bioimagetools 1.1.3
</code></pre>
  <blockquote>
   <p>
    <strong>
     Troubleshooting:
    </strong>
    <br/>
    If R complains when installing bioimagetools it may lack system-wide libraries. These would have to be installed from terminal, probably with admin rights. eg:
    <br/>
    libssl-dev:
    <code>
     sudo apt-get install libssl-dev
    </code>
    <br/>
    libcurl4:
    <code>
     sudo apt-get install libcurl4
    </code>
    <br/>
    libcurl4-openssl-dev:
    <code>
     sudo apt-get install libcurl4-openssl-dev
    </code>
    <br/>
    libtiff5-dev:
    <code>
     sudo apt-get install libtiff5-dev
    </code>
    <br/>
    EBImage:
    <br/>
    <code>
     if (!requireNamespace("BiocManager", quietly = TRUE))
    </code>
    <br/>
    <code>
     install.packages("BiocManager")
    </code>
    <br/>
    <code>
     BiocManager::install("EBImage", version = "3.8")
    </code>
    <br/>
    Or for older versions:
    <br/>
    <code>
     source("https://bioconductor.org/biocLite.R")
    </code>
    <br/>
    <code>
     biocLite("EBImage")
    </code>
   </p>
  </blockquote>
  <h4 id="octave-at-least-octave-403">
   Octave: at least Octave 4.0.3
  </h4>
  <pre><code>Octave packages:
Octave-image 2.6.1
Octave-statistics 1.3.0
</code></pre>
  <h4 id="bioformats">
   Bioformats:
  </h4>
  <pre><code>$ wget https://downloads.openmicroscopy.org/bio-formats/5.9.2/artifacts/bioformats-octave-5.9.2.tar.gz
$ octave --eval 'pkg install bioformats-octave-5.9.2.tar.gz'
</code></pre>
  <h4 id="java">
   Java:
  </h4>
  <p>
   Need to also make a text file in your home:
   <code>
    ~/javaclasspath.txt
   </code>
   <br/>
   with this inside:
   <code>
    /usr/local/share/java/bioformats_package.jar
   </code>
   <br/>
   To guide bioformats to the location of the bioformats_package.jar located on the machine.
   <br/>
   If you are doing this on your own machine the PATH you write inside the javaclasspath file will change.
  </p>
  <p>
   see:
   <a href="https://docs.openmicroscopy.org/bio-formats/5.8.1/users/octave/index.html">
    https://docs.openmicroscopy.org/bio-formats/5.8.1/users/octave/index.html
   </a>
  </p>
  <h4 id="graphicsmagick-1323">
   GraphicsMagick-1.3.23
  </h4>
  <p>
   A library for working with images.
  </p>
  <blockquote>
   <h4 id="misc">
    Misc
   </h4>
   <p>
    There is a chance I’ve forgotten some basic library in this brief desciption.
    <br/>
    Basically if Cha
    <em>
     i
    </em>
    N complains at the start because it requires a library it should tell you what is missing.
   </p>
  </blockquote>
  <h2 id="how-to-chain">
   How to Cha
   <em>
    i
   </em>
   N:
  </h2>
  <p>
   Lemme show you. You’ll need two types of
   <em>
    “raw”
   </em>
   data.
   <br/>
   Files ending in
   <code>
    *SIR_THR_ALN.tif
   </code>
   &amp;
   <code>
    ALN_MCNR-mask.tif
   </code>
   <br/>
   These are not true raw
   <code>
    .tif
   </code>
   files. The first is the reconstructed raw (SIR) which has been processed by the script
   <code>
    16THR.ijm
   </code>
   . This is an custom ImageJ macro for Fiji which utilises the
   <strong>
    SIMcheck
   </strong>
   plugging from Micron to threshold the image to the modal value (assumed to be background) and converts the image to a 16 bit tiff.
  </p>
  <p>
   In the process it also uses the true raw for
   <strong>
    SIMcheck
   </strong>
   to generate a modulation contrast map, the second file required.
  </p>
  <p>
   Both files need to be aligned, currently using
   <strong>
    Chromagnon
   </strong>
   .
  </p>
  <h3 id="where-is-the-raw-data">
   Where is the raw data?
  </h3>
  <p>
   The raw data is far too large to keep under version control (each SIM result is around 150MB after conversion to 16bit). At the moment it is assumed that the files exist in the
   <code>
    /data
   </code>
   directory but we will come up with something better later. Maybe using our omero server to serve this files. To meet this assumption currently you just have to copy the data to be processed into the actual Cha
   <em>
    i
   </em>
   n
   <code>
    /data
   </code>
   directory.
   <br/>
   The output will be in the Cha
   <em>
    i
   </em>
   n
   <code>
    /results
   </code>
   directory.
  </p>
  <blockquote>
   <p>
    Previously when Cha
    <em>
     i
    </em>
    N was in a different machine than the micron server, data was mounted as read only using
    <code>
     sshfs
    </code>
    from whichever directory it was in, into Cha
    <em>
     i
    </em>
    N’s
    <code>
     /data
    </code>
    directory.
    <br/>
    Can’t use
    <code>
     sshfs
    </code>
    because 2125 does not have it installed
    <br/>
    Can’t used mount (below) because I need to be root.
    <br/>
    This mounting does not currently work:
    <br/>
    Mount data as read-only
    <br/>
    <code>
     $ mount -Br ~/path/to/data ~/Chain/2chan/data
    </code>
    <br/>
    Mount results
    <br/>
    <code>
     mount -B ~/path/to/results ~/Chain/2chan/results
    </code>
   </p>
  </blockquote>
  <h3 id="how-to-structure-and-name-raw-data">
   How to structure and name raw data
  </h3>
  <p>
   The raw data to be processed by Cha
   <em>
    i
   </em>
   N can be organised in whatever architecture is required. The results data will be saved in an architecture mimicking that of the input.
   <br/>
   However, for ease of compiling al results
   <code>
    *.csv
   </code>
   tables afterwards it is recommeded to organise the data under the following structure:
   <code>
    /data/cell-type/exp-condition/chrom-marker
   </code>
   . eg:
   <code>
    /data/C127/G1/CTCF
   </code>
  </p>
  <p>
   Make sure that the name of the directories is the same as the tags included in the file name:
   <br/>
   <code>
    [experiment-code]_[microscope-slide-number]_[cell-type]_[experimental-condition]_[acquisition-oil]_[wavelength]_[chromatin-marker]_[acquisition-number]_[FILE-TYPE]
   </code>
   <br/>
   i.e., for the previous example, a file would be:
   <br/>
   <code>
    2018-07-03_1_C127_Trip_G1_514_Scc1-488_CTCF-594_04_SIR_THR_ALN.tif
   </code>
  </p>
  <h3 id="the-makefile">
   The Makefile
  </h3>
  <p>
   The numerous R and Octave scripts that form the basis of image analysis in this pipeline are managed under the
   <strong>
    Make
   </strong>
   build system. One can still call up any of these scripts individually to process a single file (or number of files a script requires) but this is not necessary.
   <br/>
   In the Cha
   <em>
    i
   </em>
   N directory there is a file called
   <code>
    Makefile
   </code>
   with the instructions about what each script requires and what it should output.
   <br/>
   Furthermore the
   <code>
    Makefile
   </code>
   has instructions to look for the files appropriate
   <code>
    .tif
   </code>
   files (as mentioned previously) in the
   <code>
    /data
   </code>
   directory. It will mimick the subdirectory architecture when saving all output files to the
   <code>
    /results
   </code>
   directory.
   <br/>
   On top of this, the relationship between the ouptut of some of the scripts as inputs for others downstream is coded in the makefile, such that
   <strong>
    Make
   </strong>
   can generate all required intermediate files if asked for an ouptut.
   <br/>
   If running this analysis on a machine with enough memory and ram to handle paralleled image processing
   <strong>
    Make
   </strong>
   is also able to parallelize jobs, greatly reducing the time required for processing large numbers of images.
  </p>
  <blockquote>
   <p>
    $ make command
    <br/>
    or
   </p>
   <p>
    $ make -j
    <strong>
     n
    </strong>
    command
   </p>
   <p>
    where
    <strong>
     n
    </strong>
    is the number of parallel jobs requred
   </p>
  </blockquote>
  <p>
   Finally
   <strong>
    Make
   </strong>
   is able to recognize when files have been processed already do calling a function twice does not result in unnecessary processing of the same data that had previously been analysed. Only new data will be processed.
  </p>
  <p>
   The
   <code>
    Makefile
   </code>
   includes a short guideline of the analyses available which can be called by:
   <br/>
   $ make help
  </p>
  <p>
   Here are some examples of how to process files:
  </p>
  <blockquote>
   <p>
    Depending on the details of the Makefile the actual file title endings may be slighly differently processed
   </p>
  </blockquote>
  <h4 id="nucleus-mask">
   Nucleus mask:
  </h4>
  <pre><code>$ make mask
</code></pre>
  <p>
   <strong>
    Input:
   </strong>
   Reconstructed, thresholded and aligned data.
  </p>
  <blockquote>
   <p>
    the order of alignment and thresholding has changed due to the alignment software changes, thus files could be
    <code>
     *_SIR_THR_ALN.tif
    </code>
    or
    <code>
     *_SIR_EAL_THR.tif
    </code>
    . This
    <strong>
     WILL
    </strong>
    affect the ability of the Makefile to find these files so the recipes in the Makefile will have to be changed accordingly (see section below).
   </p>
  </blockquote>
  <p>
   <strong>
    script:
   </strong>
   <code>
    nucleus_mask.m
   </code>
  </p>
  <p>
   To make a
   <code>
    .tif
   </code>
   mask from the chromatin stain which will be the outline of the nucleus.
   <br/>
   <strong>
    Output:
   </strong>
   <code>
    *_mask.tif
   </code>
  </p>
  <h4 id="replication-mask">
   Replication mask:
  </h4>
  <pre><code>$ make submask
</code></pre>
  <p>
   Will process all
   <code>
    EdU
   </code>
   files.
   <br/>
   To make a
   <code>
    .tif
   </code>
   mask from the replication regions if required to separate nascent replication from non replicating regions.
   <br/>
   Output:
   <code>
    *EdU-submask.tif
   </code>
  </p>
  <h4 id="chromatin-density-segmentation">
   Chromatin density segmentation:
  </h4>
  <pre><code>$ make segmented-chromatin
</code></pre>
  <p>
   <strong>
    Input:
   </strong>
   <code>
    results/.../*_mask.tif
   </code>
   &amp;
   <code>
    data/.../*_SIR_THR_ALN.tif
   </code>
   or
   <code>
    *_SIR_EAL_THR.tif
   </code>
   <br/>
   <strong>
    script:
   </strong>
   <code>
    chromseg.R
   </code>
   <br/>
   To make a
   <code>
    .tif
   </code>
   segmented chromatin landscape, binned into arbitrary classes inside the nuclear mask made from
   <code>
    make mask
   </code>
   <br/>
   <strong>
    Output:
   </strong>
   <code>
    *_SEG.tif
   </code>
  </p>
  <h4 id="centroids">
   Centroids:
  </h4>
  <pre><code>$ make centroids
</code></pre>
  <p>
   <strong>
    Input:
   </strong>
   <code>
    results/.../*_mask.tif
   </code>
   &amp;
   <code>
    data/.../*_SIR_THR_ALN.tif
   </code>
   or
   <code>
    *_SIR_EAL_THR.tif
   </code>
   <br/>
   <strong>
    script:
   </strong>
   <code>
    foci_centroids.m
   </code>
   <br/>
   To make a
   <code>
    .csv
   </code>
   file of
   <code>
    xyz
   </code>
   coordinates of the intensity weighted centroids from IF signals against epigenetic markers.
   <br/>
   <strong>
    Output:
   </strong>
   <code>
    *_centroids.csv
   </code>
  </p>
  <h4 id="density-ditributions">
   Density ditributions:
  </h4>
  <pre><code>$ make distributions
</code></pre>
  <p>
   <strong>
    Input:
   </strong>
   <code>
    results/.../*_centroids.csv
   </code>
   &amp;
   <code>
    results/.../*_SEG.tif
   </code>
   &amp;
   <code>
    data/.../*_MCNR-mask.tif
   </code>
   <br/>
   <strong>
    script:
   </strong>
   <code>
    distribution.R
   </code>
   <br/>
   To take the centroid coordinates from
   <code>
    make centroids
   </code>
   and index them on the segmented landscape from
   <code>
    make segmented-chromatin
   </code>
   , generating a
   <code>
    .csv
   </code>
   distribution of the number of centroids that fall in each density class.
   <br/>
   <strong>
    Output:
   </strong>
   <code>
    *_distn.csv
   </code>
  </p>
  <h4 id="chromatin-ic-boundaries">
   Chromatin-IC boundaries:
  </h4>
  <pre><code>$ make boundaries
</code></pre>
  <p>
   <strong>
    Input:
   </strong>
   <code>
    results/.../*_SEG.tif
   </code>
   <br/>
   <strong>
    script:
   </strong>
   <code>
    bound.m
   </code>
   <br/>
   To take the the segmented landscape from
   <code>
    make segmented-chromatin
   </code>
   and generate a
   <code>
    .tif
   </code>
   binary of the boundary between class 1 and all other classes.
   <br/>
   <strong>
    Output:
   </strong>
   <code>
    *_bound.tif
   </code>
  </p>
  <h4 id="distances-to-boundaries">
   Distances to boundaries:
  </h4>
  <pre><code>$ make d2b
</code></pre>
  <p>
   <strong>
    Input:
   </strong>
   <code>
    results/.../*_centroids.csv
   </code>
   &amp;
   <code>
    results/.../*_bound.tif
   </code>
   &amp;
   <code>
    results/.../*_masktif
   </code>
   <br/>
   <strong>
    script:
   </strong>
   <code>
    d2bound.m
   </code>
   <br/>
   To take the centroid coordinates from
   <code>
    make centroids
   </code>
   and run a nearest neighbour eucledian algorithm to voxels in the segmented boundaires from
   <code>
    make boundaries
   </code>
   , generating a
   <code>
    .csv
   </code>
   distribution of the number of centroids that fall in each density class (
   <em>
    md2b
   </em>
   ).
   <br/>
   This is also repeated for a random sample of centroids (same number as those for the biological marker) to get a baseline for the random distribution (
   <em>
    rd2b
   </em>
   )
   <br/>
   <strong>
    Output:
   </strong>
   <code>
    *_md2b.csv
   </code>
   &amp;
   <code>
    *_rd2b.csv
   </code>
  </p>
  <h4 id="distance-fit-to-model">
   Distance fit to model
  </h4>
  <pre><code>$ make d2bfit
</code></pre>
  <p>
   <strong>
    Input:
   </strong>
   <code>
    results/.../*_md2b.csv
   </code>
   &amp;
   <code>
    results/.../*_rd2b.csv
   </code>
   <br/>
   <strong>
    script:
   </strong>
   <code>
    nucleus_mask.m
   </code>
   <br/>
   To use a least squares regression to fit a
   <em>
    mu
   </em>
   and
   <em>
    sigma
   </em>
   for the available distances of the marker and the random sample from
   <code>
    make d2b
   </code>
   .
   <br/>
   <strong>
    Output:
   </strong>
   <code>
    *_d2bfit.csv
   </code>
  </p>
  <h4 id="distances-normalized">
   Distances normalized
  </h4>
  <pre><code>$ make d2bnorm
</code></pre>
  <p>
   <strong>
    Input:
   </strong>
   <code>
    results/.../*_d2bfit.csv
   </code>
   <br/>
   <strong>
    script:
   </strong>
   <code>
    nucleus_mask.m
   </code>
   <br/>
   To make normalised distances
   <code>
    make d2b
   </code>
   as log2fold enrichment simulated over +/- 400nm from the
   <em>
    mu
   </em>
   and
   <em>
    sigma
   </em>
   from
   <code>
    make d2bfit
   </code>
   .
   <br/>
   <strong>
    Output:
   </strong>
   <code>
    *_d2bnorm.csv
   </code>
  </p>
  <h3 id="tweaking-makefile-whenif-required">
   Tweaking Makefile (when/if required)
  </h3>
  <blockquote>
   <p>
    If you can help it, don’t do it.
   </p>
  </blockquote>
  <p>
   Currently need to copy all of G1 data from all the trip directories in bioc1090/data which also end in the “
   <em>
    SIR_THR_ALN.tif” and “
   </em>
   MCNR-mask.tif”:
  </p>
  <p>
   find LS2018-07-03_1_C127_Trip/ -type f ( -name “
   <em>
    G1
   </em>
   ” -and ( -name “
   <em>
    SIR_THR_ALN.tif” -or -name “
   </em>
   MCNR-mask.tif” ) ) -exec cp {} ~/papers/data/C127/Trip \;
  </p>
  <p>
   Then need to scp to a machine that can run Fiji to open all and save them as tifs again in imageJ with a OS.ijm macro.
  </p>
  <p>
   Then scp to copy them back to data in Cha
   <em>
    i
   </em>
   n.
  </p>
  <h2 id="final-data-management">
   Final data management
  </h2>
  <p>
   After processing with Cha
   <em>
    i
   </em>
   N the
   <code>
    /results
   </code>
   directory (with any created sub directories) will be filled with the output files from the image analysis.
  </p>
  <p>
   Then to aggregate the distribution and network data employ these scipts from the directory where the makefile is, in this order:
  </p>
  <ul>
   <li>
    Summary.R (
    <strong>
     input:
    </strong>
    <code>
     *_distn.csv
    </code>
    ,
    <strong>
     output:
    </strong>
    <code>
     *_distn-summary.csv
    </code>
    &amp;
    <code>
     *_distn-full.csv
    </code>
    )
    <ul>
     <li>
      spot-class-count.R (
      <strong>
       input:
      </strong>
      <code>
       *_distn.csv
      </code>
      ,
      <strong>
       output:
      </strong>
      <code>
       *_spot-class-count.csv
      </code>
      &amp;
      <code>
       *_spot-class-summaryl.csv
      </code>
      )
      <ul>
       <li>
        dist_compile.R (
        <strong>
         input:
        </strong>
        <code>
         *_distn-summary.csv
        </code>
        &amp;
        <code>
         *_spot-class-summary.csv
        </code>
        ,
        <strong>
         output:
        </strong>
        <code>
         *_distn-compile.csv
        </code>
        )
        <ul>
         <li>
          SA2vol.R (
          <strong>
           input:
          </strong>
          <code>
           *_spot-class-summary.csv
          </code>
          &amp;
          <code>
           *_bound.tif
          </code>
          ,
          <strong>
           output:
          </strong>
          <code>
           *_SA2vol_raw.csv
          </code>
          &amp;
          <code>
           *_SA2vol_stat.csv
          </code>
          &amp;
          <code>
           *_chrom2vol_stat.csv
          </code>
          )
         </li>
        </ul>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
  <p>
   To aggregate d2b data:
  </p>
  <ul>
   <li>
    summaryd2b.R (
    <strong>
     input:
    </strong>
    <code>
     .csv
    </code>
    ,
    <strong>
     output:
    </strong>
    <code>
     .csv
    </code>
    )
    <ul>
     <li>
      d2b_compile.R (
      <strong>
       input:
      </strong>
      <code>
       *_network-summary.csv
      </code>
      &amp;
      <code>
       *_abs-md2b_summary.csv
      </code>
      &amp;
      <code>
       *_d2bnorm-summary.csv
      </code>
      <strong>
       output:
      </strong>
      <code>
       *_md2b-compile.csv
      </code>
      &amp;
      <code>
       *_d2bnorm-compile.csv
      </code>
      &amp;
      <code>
       *_network-compile.csv
      </code>
      )
     </li>
    </ul>
   </li>
  </ul>
  <p>
   For changes in cell type and condition each script needs to be manually adjusted by changing those variables at the beginning of the script.
  </p>
  <h3 id="making-plots">
   Making plots:
  </h3>
  <p>
   Below are the scripts used to generate the graphs in the paper. These scripts cannot be run from terminal as Rscript [path-to-script].
   <br/>
   They should be opened in R (or R studio) to asses them. They are all comprised of multiple semgents each outputting different kind of graphs and requiring input of different data.
  </p>
  <h4 id="batch-distn-barplotsr">
   batch-distn-barplots.R
  </h4>
  <p>
   Required packages:
  </p>
  <pre><code>    ggplot2
    reshape2
</code></pre>
  <ul>
   <li>
    Automatically produce a barplot for each marker of its enrichment/depletion in each chromatin class ([condition]_distn-compile*.csv).
   </li>
   <li>
    Depending on the ggplot used and data uploaded the barplots can be for single condition or multiple conditions in parallel.
   </li>
   <li>
    Groups of markers can also be plotted in parallel for a single conditions (to group by function)
   </li>
   <li>
    Bar plots of WF vs SIR enrichment/depletion data for controls (“WF-distribution-summary.csv”).
   </li>
  </ul>
  <h4 id="heatmaplutr">
   heatmapLUT.R
  </h4>
  <p>
   Required packages:
  </p>
  <pre><code>    ggplot2
    scales
    RColorBrewer
</code></pre>
  <ul>
   <li>
    This will produce the heatmaps with the corrected loops (for extreme values)
   </li>
   <li>
    The variety of small ggplots to choose from include all markers for a single condition. or comparing across conditions in different panels etc.
   </li>
   <li>
    It requires the type of file with the density distributions for all markers: [condition]_distn-compile*.csv (eg: G1_distn-compile_volnormE_Final.csv)
   </li>
  </ul>
  <h4 id="distance-plotsr">
   distance-plots.R
  </h4>
  <p>
   Required packages:
  </p>
  <pre><code>    ggplot2
    RColorBrewer
</code></pre>
  <ul>
   <li>
    This will produce the dot plot of distance from IC surface for all markers in a single condition or multiple conditions in parallel.
   </li>
   <li>
    It requires the type of file with the distances for each marker: [condition]_md2b-compile*. (eg: csv G1_md2b-compile_Final.csv)
   </li>
  </ul>
  <h4 id="savolboxr">
   SAvolbox.R
  </h4>
  <p>
   Required packages:
  </p>
  <pre><code>    ggplot2
    RColorBrewer
    reshape2
    dplyr
</code></pre>
  <ul>
   <li>
    Box or violin plots of SA:vol ratios distribution (C127_[G1/NaN3/Hyper-os/Trip]_SA2vol_raw_Final.csv).
   </li>
   <li>
    Dot plot of mean SA:vol with 95CI (C127_[G1/NaN3/Hyper-os/Trip]_SA2vol_raw_Final.csv).
   </li>
   <li>
    Box or violin of chromatin vol:nuclear vol (C127_[G1/NaN3/Hyper-os/Trip]_SA2vol_raw_Final.csv).
   </li>
   <li>
    Box or violin of whole nuclear volume (C127_[G1/NaN3/Hyper-os/Trip]_SA2vol_raw_Final.csv).
   </li>
   <li>
    Changes of volumes for each density class as absolute values or normalised to nuclear volume for G1 or Sphase ([G1/ES/MS/LS]_distn-compile.csv”).
   </li>
   <li>
    Remodeller size to marker distn (from remod-size-table_Final.csv).
   </li>
   <li>
    Bar plots of WF vs SIR chromatin data for controls (“WF-distribution-summary.csv”).
   </li>
  </ul>
  <h4 id="network-dimsr">
   network-dims.R
  </h4>
  <p>
   Required packages:
  </p>
  <pre><code>    ggplot2
    plyr
</code></pre>
  <ul>
   <li>
    To plot changes in each chromatin network size as continuous line (G1_network-compile.csv)
   </li>
   <li>
    To work out the network radius from a tubular model and plot the radius as point with 95CI bars or the network diameter
   </li>
  </ul>
  <script src="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.1/highlight.min.js">
  </script>
  <script>
   hljs.initHighlightingOnLoad();
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript">
  </script>
  <script type="text/javascript">
   MathJax.Hub.Config({"showProcessingMessages" : false,"messageStyle" : "none","tex2jax": { inlineMath: [ [ "$", "$" ] ] }});
  </script>
 </body>
</html>